{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2NWfQUKheCm"
      },
      "source": [
        "!pip -q install -U fastapi pydantic email-validator uvicorn\n",
        "import sys, json, re, uuid, csv, io, asyncio, hmac, hashlib, random\n",
        "from typing import List, Dict, Tuple, Optional, Any, Callable, Set\n",
        "from collections import deque, OrderedDict, defaultdict\n",
        "from datetime import datetime, timedelta\n",
        "from io import StringIO\n",
        "from fastapi import FastAPI, Header, HTTPException\n",
        "from pydantic import BaseModel, EmailStr, constr\n",
        "\n"
      ],
      "id": "Z2NWfQUKheCm",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYOnzD9NheCq",
        "outputId": "703b0515-796c-437e-ba59-293e6ea6626a"
      },
      "source": [
        "import random, csv, json, os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "random.seed(7)\n",
        "\n",
        "def rand_phone():\n",
        "    s = \"\".join(random.choice(\"0123456789\") for _ in range(10))\n",
        "    return f\"({s[0:3]}) {s[3:6]}-{s[6:10]}\"\n",
        "\n",
        "def rand_email(name, i):\n",
        "    doms = [\"alpha.com\",\"beta.io\",\"gamma.org\"]\n",
        "    d = random.choice(doms)\n",
        "    if i % 5 == 0:\n",
        "        return f\"{name}@{d}\".upper()\n",
        "    return f\"{name}@{d}\"\n",
        "\n",
        "def iso(dt):\n",
        "    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "\n",
        "now = datetime(2025,8,10,10,0,0)\n",
        "\n",
        "contacts = []\n",
        "for i in range(1,31):\n",
        "    name = f\"user{i}\"\n",
        "    email = rand_email(name, i)\n",
        "    phone = rand_phone()\n",
        "    if i % 7 == 0:\n",
        "        phone = phone if i % 14 == 0 else contacts[-1][\"phone\"]\n",
        "    updated = now - timedelta(hours=random.randint(0,72))\n",
        "    contacts.append({\"id\":str(i),\"name\":name,\"email\":email,\"phone\":phone,\"updated_at\":iso(updated)})\n",
        "\n",
        "leads = []\n",
        "owners = [\"u1\",\"u2\",\"u3\"]\n",
        "for i,c in enumerate(contacts[:20], start=1):\n",
        "    created = now - timedelta(days=random.randint(0,14), hours=random.randint(0,10))\n",
        "    converted = (i % 3 == 0)\n",
        "    leads.append({\n",
        "        \"id\":f\"L{i}\",\n",
        "        \"email\":c[\"email\"].lower(),\n",
        "        \"owner_id\":random.choice(owners),\n",
        "        \"created_at\":iso(created),\n",
        "        \"converted_at\":iso(created+timedelta(days=3)) if converted else None\n",
        "    })\n",
        "\n",
        "opportunities = []\n",
        "for i,l in enumerate(leads, start=1):\n",
        "    if i % 2 == 0:\n",
        "        stage = \"Closed Won\" if i % 4 == 0 else \"Open\"\n",
        "        opportunities.append({\n",
        "            \"id\":f\"O{i}\",\n",
        "            \"account_id\":str((i%10)+1),\n",
        "            \"amount\":1000+100*i,\n",
        "            \"stage\":stage,\n",
        "            \"owner_id\":l[\"owner_id\"],\n",
        "            \"lead_id\":l[\"id\"],\n",
        "            \"created_at\":l[\"created_at\"],\n",
        "            \"updated_at\":l[\"created_at\"]\n",
        "        })\n",
        "\n",
        "tasks = []\n",
        "for i in range(1,16):\n",
        "    due = now + timedelta(minutes=random.choice([5,10,20,40,60]))\n",
        "    status = \"open\" if i % 3 != 0 else \"done\"\n",
        "    tasks.append({\"id\":str(i),\"owner_id\":random.choice(owners),\"contact_id\":str(random.randint(1,30)),\"due_at\":iso(due),\"status\":status})\n",
        "\n",
        "logins = []\n",
        "for u in range(1,6):\n",
        "    first = datetime(2025,1,1) + timedelta(days=random.randint(0,20))\n",
        "    for m in range(0,6):\n",
        "        if random.random() < 0.7:\n",
        "            ts = first + timedelta(days=30*m+random.randint(0,5))\n",
        "            logins.append({\"user_id\":f\"U{u}\",\"ts\":iso(ts)})\n",
        "\n",
        "db = {\"contacts\":contacts,\"leads\":leads,\"opportunities\":opportunities,\"tasks\":tasks,\"logins\":logins}\n",
        "\n",
        "with open(\"/content/crm_data.json\",\"w\") as f:\n",
        "    json.dump(db,f)\n",
        "with open(\"/content/contacts.csv\",\"w\",newline=\"\") as f:\n",
        "    w = csv.DictWriter(f, fieldnames=[\"id\",\"name\",\"email\",\"phone\",\"updated_at\"])\n",
        "    w.writeheader()\n",
        "    for r in contacts:\n",
        "        w.writerow(r)\n",
        "\n",
        "print(\"data_ready\", len(contacts), len(leads), len(opportunities), len(tasks), len(logins))\n"
      ],
      "id": "vYOnzD9NheCq",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_ready 30 20 10 15 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re, csv, asyncio, hashlib, hmac, uuid, json\n",
        "from typing import List, Dict, Tuple, Optional, Any, Callable, Set\n",
        "from collections import deque, OrderedDict, defaultdict\n",
        "from datetime import datetime, timedelta\n",
        "from io import StringIO\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel, EmailStr, constr\n",
        "\n",
        "def normalize_email(s: Optional[str]) -> Optional[str]:\n",
        "    if not s: return None\n",
        "    s = s.strip().lower()\n",
        "    return s or None\n",
        "\n",
        "def normalize_phone(s: Optional[str]) -> Optional[str]:\n",
        "    if not s: return None\n",
        "    digits = re.sub(r\"\\D\",\"\",s)\n",
        "    if digits.startswith(\"1\") and len(digits) == 11:\n",
        "        digits = digits[1:]\n",
        "    return digits or None\n",
        "\n",
        "def dedupe_contacts(records: List[Dict]) -> Tuple[List[Dict], Dict[str, str]]:\n",
        "    seen = {}\n",
        "    survivors = {}\n",
        "    dup_map = {}\n",
        "    for r in records:\n",
        "        rid = str(r.get(\"id\"))\n",
        "        e = normalize_email(r.get(\"email\"))\n",
        "        p = normalize_phone(r.get(\"phone\"))\n",
        "        k = (\"e\", e) if e else (\"p\", p) if p else (\"id\", rid)\n",
        "        if k in seen:\n",
        "            sid = seen[k]\n",
        "            sr = survivors[sid]\n",
        "            sr[\"email\"] = sr.get(\"email\") or r.get(\"email\")\n",
        "            sr[\"phone\"] = sr.get(\"phone\") or r.get(\"phone\")\n",
        "            dup_map[rid] = sid\n",
        "        else:\n",
        "            seen[k] = rid\n",
        "            survivors[rid] = dict(r)\n",
        "    return list(survivors.values()), dup_map\n",
        "\n",
        "def import_contacts_csv(csv_text: str, store: Dict[str, Dict[str, Any]]) -> Tuple[int,int]:\n",
        "    added = 0\n",
        "    updated = 0\n",
        "    f = StringIO(csv_text)\n",
        "    for row in csv.DictReader(f):\n",
        "        email = row.get(\"email\",\"\").strip().lower()\n",
        "        if not email:\n",
        "            continue\n",
        "        if email in store:\n",
        "            before = dict(store[email])\n",
        "            store[email].update(row)\n",
        "            if store[email] != before:\n",
        "                updated += 1\n",
        "        else:\n",
        "            store[email] = dict(row)\n",
        "            added += 1\n",
        "    return added, updated\n",
        "\n",
        "class RateLimiter:\n",
        "    def __init__(self, limit: int, window_seconds: int):\n",
        "        self.limit = limit\n",
        "        self.window = window_seconds\n",
        "        self.qs: Dict[str, deque] = {}\n",
        "    def allow(self, user_id: str, now: float = None) -> bool:\n",
        "        if now is None:\n",
        "            now = datetime.now().timestamp()\n",
        "        q = self.qs.setdefault(user_id, deque())\n",
        "        cutoff = now - self.window\n",
        "        while q and q[0] <= cutoff:\n",
        "            q.popleft()\n",
        "        if len(q) < self.limit:\n",
        "            q.append(now)\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "class IdempotencyStore:\n",
        "    def __init__(self):\n",
        "        self.store: Dict[str, Tuple[Any, bool]] = {}\n",
        "    def call(self, key: str, fn: Callable[[], Any]) -> Any:\n",
        "        if key in self.store:\n",
        "            v, ok = self.store[key]\n",
        "            if ok:\n",
        "                return v\n",
        "        try:\n",
        "            v = fn()\n",
        "            self.store[key] = (v, True)\n",
        "            return v\n",
        "        except Exception as e:\n",
        "            self.store[key] = (e, False)\n",
        "            raise\n",
        "\n",
        "def parse_ts(s: str) -> float:\n",
        "    return datetime.fromisoformat(s).timestamp()\n",
        "\n",
        "def page_items(items: List[Dict], size: int, after: Optional[Tuple[float,str]]):\n",
        "    arr = sorted(items, key=lambda r: (parse_ts(r[\"updated_at\"]), r[\"id\"]), reverse=True)\n",
        "    start = 0\n",
        "    if after is not None:\n",
        "        for i, r in enumerate(arr):\n",
        "            if (parse_ts(r[\"updated_at\"]), r[\"id\"]) == after:\n",
        "                start = i + 1\n",
        "                break\n",
        "    slice_ = arr[start:start+size]\n",
        "    next_after = None\n",
        "    if len(slice_) == size:\n",
        "        last = slice_[-1]\n",
        "        next_after = (parse_ts(last[\"updated_at\"]), last[\"id\"])\n",
        "    return slice_, next_after\n",
        "\n",
        "def due_tasks(tasks: List[Dict], now: datetime, within_minutes: int) -> List[Dict]:\n",
        "    end = now + timedelta(minutes=within_minutes)\n",
        "    out = []\n",
        "    for t in tasks:\n",
        "        ts = datetime.fromisoformat(t[\"due_at\"])\n",
        "        if now <= ts <= end and t.get(\"status\",\"open\") == \"open\":\n",
        "            out.append(t)\n",
        "    return sorted(out, key=lambda x: (x[\"due_at\"], x[\"id\"]))\n",
        "\n",
        "def verify_signature(secret: str, payload: bytes, signature: str) -> bool:\n",
        "    mac = hmac.new(secret.encode(), payload, hashlib.sha256).hexdigest()\n",
        "    return hmac.compare_digest(mac, signature.lower())\n",
        "\n",
        "def weekly_conversion(leads: List[Dict]) -> List[Dict]:\n",
        "    def wk(dt: datetime):\n",
        "        y, w, _ = dt.isocalendar()\n",
        "        return f\"{y}-W{w:02d}\"\n",
        "    total = defaultdict(int)\n",
        "    converted = defaultdict(int)\n",
        "    for l in leads:\n",
        "        d = datetime.fromisoformat(l[\"created_at\"])\n",
        "        key = wk(d)\n",
        "        total[key] += 1\n",
        "        if l.get(\"converted_at\"):\n",
        "            converted[key] += 1\n",
        "    out = []\n",
        "    for k in sorted(total.keys()):\n",
        "        t = total[k]\n",
        "        c = converted[k]\n",
        "        rate = c / t if t else 0.0\n",
        "        out.append({\"week\": k, \"total\": t, \"converted\": c, \"rate\": rate})\n",
        "    return out\n",
        "\n",
        "class LRU:\n",
        "    def __init__(self, capacity: int):\n",
        "        self.cap = capacity\n",
        "        self.od = OrderedDict()\n",
        "    def get(self, k: str):\n",
        "        if k not in self.od:\n",
        "            return None\n",
        "        v = self.od.pop(k)\n",
        "        self.od[k] = v\n",
        "        return v\n",
        "    def put(self, k: str, v: Any):\n",
        "        if k in self.od:\n",
        "            self.od.pop(k)\n",
        "        elif len(self.od) >= self.cap:\n",
        "            self.od.popitem(last=False)\n",
        "        self.od[k] = v\n",
        "\n",
        "def merge_records(a: Dict[str,Any], b: Dict[str,Any], prefer: str) -> Tuple[Dict[str,Any], Dict[str,Tuple[Any,Any]]]:\n",
        "    out = dict(a if prefer==\"a\" else b)\n",
        "    other = b if prefer==\"a\" else a\n",
        "    out2 = dict(out)\n",
        "    out2.update({k:v for k,v in other.items() if k not in out or out[k] in (None,\"\")})\n",
        "    diff = {}\n",
        "    keys = set(a.keys()) | set(b.keys())\n",
        "    for k in keys:\n",
        "        va = a.get(k)\n",
        "        vb = b.get(k)\n",
        "        if va != vb:\n",
        "            diff[k] = (va, vb)\n",
        "    return out2, diff\n",
        "\n",
        "Role = str\n",
        "Action = str\n",
        "PERMS: Dict[Role, Set[Action]] = {\n",
        "    \"admin\": {\"read:any\",\"write:any\"},\n",
        "    \"manager\": {\"read:any\",\"write:team\"},\n",
        "    \"rep\": {\"read:own\",\"write:own\"},\n",
        "}\n",
        "\n",
        "def can(action: Action, role: Role, owner_id: str, user_id: str, team_ok: bool=False) -> bool:\n",
        "    p = PERMS.get(role, set())\n",
        "    if \"read:any\" in p and action.startswith(\"read\"): return True\n",
        "    if \"write:any\" in p and action.startswith(\"write\"): return True\n",
        "    if \"write:team\" in p and action.startswith(\"write\") and team_ok: return True\n",
        "    if \"read:any\" in p and action.startswith(\"search\"): return True\n",
        "    if \"read:own\" in p and owner_id == user_id and action.startswith((\"read\",\"search\")): return True\n",
        "    if \"write:own\" in p and owner_id == user_id and action.startswith(\"write\"): return True\n",
        "    return False\n",
        "\n",
        "def leads_per_owner_month(leads: List[Dict]) -> List[Dict]:\n",
        "    agg = defaultdict(int)\n",
        "    for r in leads:\n",
        "        dt = datetime.fromisoformat(r[\"created_at\"])\n",
        "        k = (r.get(\"owner_id\",\"\"), f\"{dt.year}-{dt.month:02d}\")\n",
        "        agg[k] += 1\n",
        "    out = [{\"owner_id\":k[0],\"month\":k[1],\"total\":v} for k,v in agg.items()]\n",
        "    out.sort(key=lambda x: (x[\"month\"], x[\"owner_id\"]))\n",
        "    return out\n",
        "\n",
        "class Mailer:\n",
        "    def __init__(self):\n",
        "        self.q: asyncio.Queue = asyncio.Queue()\n",
        "    async def enqueue(self, msg: Dict[str,Any]) -> None:\n",
        "        await self.q.put(msg)\n",
        "    async def run(self, send_fn: Callable[[Dict[str,Any]],Any]) -> None:\n",
        "        while True:\n",
        "            msg = await self.q.get()\n",
        "            try:\n",
        "                send_fn(msg)\n",
        "            finally:\n",
        "                self.q.task_done()\n",
        "\n",
        "def export_opportunities_csv(opps: List[Dict], since_iso: str) -> str:\n",
        "    headers = [\"id\",\"account_id\",\"amount\",\"stage\",\"owner_id\",\"created_at\",\"updated_at\"]\n",
        "    f = StringIO()\n",
        "    w = csv.DictWriter(f, fieldnames=headers)\n",
        "    w.writeheader()\n",
        "    for o in opps:\n",
        "        if o[\"updated_at\"] >= since_iso:\n",
        "            w.writerow({k:o.get(k,\"\") for k in headers})\n",
        "    return f.getvalue()\n",
        "\n",
        "def import_contacts_csv_text(csv_text: str, store: Dict[str, Dict[str, Any]]) -> Dict[str,int]:\n",
        "    added = updated = 0\n",
        "    f = StringIO(csv_text)\n",
        "    for row in csv.DictReader(f):\n",
        "        email = row.get(\"email\",\"\").strip().lower()\n",
        "        if not email:\n",
        "            continue\n",
        "        if email in store:\n",
        "            before = dict(store[email])\n",
        "            store[email].update(row)\n",
        "            if store[email] != before:\n",
        "                updated += 1\n",
        "        else:\n",
        "            store[email] = dict(row)\n",
        "            added += 1\n",
        "    return {\"added\":added,\"updated\":updated}\n",
        "\n",
        "def apply_update_with_audit(entity: Dict[str,Any], changes: Dict[str,Any], user_id: str, audit_log: List[Dict[str,Any]]) -> Dict[str,Any]:\n",
        "    before = {k: entity.get(k) for k in changes.keys()}\n",
        "    entity.update(changes)\n",
        "    after = {k: entity.get(k) for k in changes.keys()}\n",
        "    audit_log.append({\"at\": datetime.utcnow().isoformat(),\"user_id\": user_id,\"entity_id\": str(entity.get(\"id\",\"\")),\"before\": before,\"after\": after})\n",
        "    return entity\n",
        "\n",
        "def sync_external_contacts(external_rows: List[Dict[str,Any]], store: Dict[str,Dict[str,Any]]) -> Dict[str,int]:\n",
        "    added = updated = 0\n",
        "    for r in external_rows:\n",
        "        e = normalize_email(r.get(\"email\"))\n",
        "        p = normalize_phone(r.get(\"phone\"))\n",
        "        if not e and not p:\n",
        "            continue\n",
        "        k = e or p\n",
        "        if k in store:\n",
        "            before = dict(store[k])\n",
        "            if e: store[k][\"email\"] = e\n",
        "            if p: store[k][\"phone\"] = p\n",
        "            for fld in (\"name\",\"source\",\"updated_at\"):\n",
        "                if r.get(fld) not in (None,\"\"): store[k][fld] = r.get(fld)\n",
        "            if store[k] != before:\n",
        "                updated += 1\n",
        "        else:\n",
        "            store[k] = {\"id\":r.get(\"id\",k),\"name\":r.get(\"name\",\"\"),\"email\":e,\"phone\":p,\"source\":r.get(\"source\"),\"updated_at\":r.get(\"updated_at\")}\n",
        "            added += 1\n",
        "    return {\"added\":added,\"updated\":updated}\n",
        "\n",
        "def funnel_metrics(leads: List[Dict], opps: List[Dict]) -> Dict[str,Any]:\n",
        "    lead_ids = {str(x.get(\"id\")) for x in leads}\n",
        "    opp_by_lead = {str(o.get(\"lead_id\")): o for o in opps if o.get(\"lead_id\") is not None}\n",
        "    n_leads = len(lead_ids)\n",
        "    n_opps = sum(1 for lid in lead_ids if lid in opp_by_lead)\n",
        "    n_won = sum(1 for lid in lead_ids if lid in opp_by_lead and str(opp_by_lead[lid].get(\"stage\")) == \"Closed Won\")\n",
        "    r_lo = (n_opps / n_leads) if n_leads else 0.0\n",
        "    r_ow = (n_won / n_opps) if n_opps else 0.0\n",
        "    r_lw = (n_won / n_leads) if n_leads else 0.0\n",
        "    return {\"leads\": n_leads,\"opportunities\": n_opps,\"won\": n_won,\"rate_lead_to_opp\": r_lo,\"rate_opp_to_won\": r_ow,\"rate_lead_to_won\": r_lw}\n",
        "\n",
        "def _ts(s: str) -> float:\n",
        "    return datetime.fromisoformat(s).timestamp()\n",
        "\n",
        "def search_and_page_contacts(contacts: List[Dict], q: str, size: int, after: Optional[Tuple[float,str]]) -> Tuple[List[Dict], Optional[Tuple[float,str]]]:\n",
        "    ql = q.strip().lower()\n",
        "    filt = []\n",
        "    for c in contacts:\n",
        "        name = (c.get(\"name\") or \"\").lower()\n",
        "        email = (c.get(\"email\") or \"\").lower()\n",
        "        if ql in name or ql in email:\n",
        "            filt.append(c)\n",
        "    arr = sorted(filt, key=lambda r: (_ts(r.get(\"updated_at\",\"1970-01-01T00:00:00\")), str(r.get(\"id\",\"\"))), reverse=True)\n",
        "    start = 0\n",
        "    if after is not None:\n",
        "        for i,r in enumerate(arr):\n",
        "            if (_ts(r.get(\"updated_at\",\"1970-01-01T00:00:00\")), str(r.get(\"id\",\"\"))) == after:\n",
        "                start = i + 1\n",
        "                break\n",
        "    page = arr[start:start+size]\n",
        "    nxt = None\n",
        "    if len(page) == size:\n",
        "        last = page[-1]\n",
        "        nxt = (_ts(last.get(\"updated_at\",\"1970-01-01T00:00:00\")), str(last.get(\"id\",\"\")))\n",
        "    return page, nxt\n",
        "\n",
        "def monthly_cohort_retention(logins: List[Dict]) -> List[Dict]:\n",
        "    first = {}\n",
        "    for r in logins:\n",
        "        u = str(r[\"user_id\"])\n",
        "        dt = datetime.fromisoformat(r[\"ts\"])\n",
        "        m = f\"{dt.year}-{dt.month:02d}\"\n",
        "        if u not in first: first[u] = m\n",
        "    cohorts = {}\n",
        "    for r in logins:\n",
        "        u = str(r[\"user_id\"])\n",
        "        dt = datetime.fromisoformat(r[\"ts\"])\n",
        "        m = f\"{dt.year}-{dt.month:02d}\"\n",
        "        c = first[u]\n",
        "        cohorts.setdefault(c, {}).setdefault(m, set()).add(u)\n",
        "    out = []\n",
        "    for c, buckets in cohorts.items():\n",
        "        users = set().union(*buckets.values())\n",
        "        size = len({u for u in users})\n",
        "        months = sorted(buckets.keys())\n",
        "        row = {\"cohort\": c, \"size\": size}\n",
        "        for m2 in months:\n",
        "            row[m2] = len(buckets[m2])\n",
        "        out.append(row)\n",
        "    out.sort(key=lambda x: x[\"cohort\"])\n",
        "    return out\n",
        "\n",
        "def upsert_contact(store: Dict[str,Dict[str,Any]], row: Dict[str,Any]) -> Dict[str,Any]:\n",
        "    e = normalize_email(row.get(\"email\"))\n",
        "    p = normalize_phone(row.get(\"phone\"))\n",
        "    k = e or p or str(row.get(\"id\"))\n",
        "    if k in store:\n",
        "        store[k].update({k2:v for k2,v in row.items() if v not in (None,\"\")})\n",
        "        return store[k]\n",
        "    store[k] = dict(row)\n",
        "    if e: store[k][\"email\"] = e\n",
        "    if p: store[k][\"phone\"] = p\n",
        "    return store[k]\n",
        "\n",
        "def dedupe_contacts_simpler(records: List[Dict]) -> Tuple[List[Dict], Dict[str, str]]:\n",
        "    def rid_or_new(r: Dict) -> str:\n",
        "        rid = r.get(\"id\")\n",
        "        return str(rid) if rid is not None else f\"tmp:{uuid.uuid4().hex}\"\n",
        "    parent: Dict[str, str] = {}\n",
        "    rank: Dict[str, int] = {}\n",
        "    order: Dict[str, int] = {}\n",
        "    def find(x: str) -> str:\n",
        "        while parent[x] != x:\n",
        "            parent[x] = parent[parent[x]]\n",
        "            x = parent[x]\n",
        "        return x\n",
        "    def union(a: str, b: str):\n",
        "        ra, rb = find(a), find(b)\n",
        "        if ra == rb: return\n",
        "        if rank[ra] < rank[rb] or (rank[ra] == rank[rb] and order[ra] > order[rb]):\n",
        "            ra, rb = rb, ra\n",
        "        parent[rb] = ra\n",
        "        if rank[ra] == rank[rb]:\n",
        "            rank[ra] += 1\n",
        "    key_owner: Dict[Tuple[str, str], str] = {}\n",
        "    rows: Dict[str, Dict] = {}\n",
        "    ids_in_order: List[str] = []\n",
        "    for i, r in enumerate(records):\n",
        "        rid = rid_or_new(r)\n",
        "        if rid not in parent:\n",
        "            parent[rid] = rid\n",
        "            rank[rid] = 0\n",
        "            order[rid] = i\n",
        "            rows[rid] = dict(r)\n",
        "            ids_in_order.append(rid)\n",
        "        e = normalize_email(r.get(\"email\"))\n",
        "        p = normalize_phone(r.get(\"phone\"))\n",
        "        keys = []\n",
        "        if e: keys.append((\"e\", e))\n",
        "        if p: keys.append((\"p\", p))\n",
        "        keys.append((\"id\", rid))\n",
        "        for k in keys:\n",
        "            if k in key_owner:\n",
        "                union(rid, key_owner[k])\n",
        "            else:\n",
        "                key_owner[k] = rid\n",
        "    groups: Dict[str, List[str]] = {}\n",
        "    for rid in ids_in_order:\n",
        "        root = find(rid)\n",
        "        groups.setdefault(root, []).append(rid)\n",
        "    survivors: List[Dict] = []\n",
        "    dup_map: Dict[str, str] = {}\n",
        "    for root, member_ids in groups.items():\n",
        "        primary = min(member_ids, key=lambda x: order[x])\n",
        "        merged = dict(rows[primary])\n",
        "        for mid in sorted(member_ids, key=lambda x: order[x]):\n",
        "            if mid == primary: continue\n",
        "            for field, val in rows[mid].items():\n",
        "                if (field not in merged) or (not merged[field]):\n",
        "                    merged[field] = val\n",
        "            dup_map[mid] = primary\n",
        "        survivors.append(merged)\n",
        "    return survivors, dup_map\n",
        "\n",
        "app = FastAPI()\n",
        "DB = {}\n",
        "IDEMP = {}\n",
        "\n",
        "class LeadIn(BaseModel):\n",
        "    email: EmailStr\n",
        "    name: constr(min_length=1)\n",
        "    source: Optional[str] = None\n",
        "\n",
        "def idem_key(raw: str) -> str:\n",
        "    return hashlib.sha256(raw.encode()).hexdigest()\n",
        "\n",
        "def create_lead(body: LeadIn, idempotency_key: Optional[str] = None):\n",
        "    if not idempotency_key:\n",
        "        raise HTTPException(status_code=400, detail=\"Missing Idempotency-Key\")\n",
        "    k = idem_key(idempotency_key + body.email)\n",
        "    if k in IDEMP:\n",
        "        return IDEMP[k]\n",
        "    if body.email in DB:\n",
        "        raise HTTPException(status_code=409, detail=\"Lead exists\")\n",
        "    DB[body.email] = {\"email\": body.email, \"name\": body.name, \"source\": body.source}\n",
        "    IDEMP[k] = DB[body.email]\n",
        "    return DB[body.email]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r68y_Bc6ieCZ"
      },
      "id": "r68y_Bc6ieCZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json, asyncio, hmac, hashlib\n",
        "from datetime import datetime\n",
        "\n",
        "with open(\"/content/crm_data.json\") as f:\n",
        "    d = json.load(f)\n",
        "\n",
        "contacts = d[\"contacts\"]\n",
        "leads = d[\"leads\"]\n",
        "opps = d[\"opportunities\"]\n",
        "tasks = d[\"tasks\"]\n",
        "logins = d[\"logins\"]\n",
        "\n",
        "survivors, dup = dedupe_contacts(contacts)\n",
        "print(\"dedupe\", len(survivors), len(dup))\n",
        "\n",
        "csv_text = \"email,name,phone\\nx@a.com,X,111\\nx@a.com,X2,111\\ny@a.com,Y,222\\n\"\n",
        "store = {}\n",
        "a,u = import_contacts_csv(csv_text, store)\n",
        "print(\"csv_upsert\", a, u, store[\"x@a.com\"][\"name\"])\n",
        "\n",
        "rl = RateLimiter(2, 60)\n",
        "print(\"rate\", rl.allow(\"u\", now=0.0), rl.allow(\"u\", now=1.0), rl.allow(\"u\", now=59.0), rl.allow(\"u\", now=61.0))\n",
        "\n",
        "calls = {\"n\":0}\n",
        "def f():\n",
        "    calls[\"n\"] += 1\n",
        "    return 42\n",
        "st = IdempotencyStore()\n",
        "print(\"idem\", st.call(\"k\", f), st.call(\"k\", f), calls[\"n\"])\n",
        "\n",
        "p1, nxt = page_items(contacts, 5, None)\n",
        "p2, nxt2 = page_items(contacts, 5, nxt)\n",
        "print(\"page\", len(p1), bool(nxt), len(p2), bool(nxt2))\n",
        "\n",
        "now = datetime(2025,8,10,10,0,0)\n",
        "dtasks = due_tasks(tasks, now, 30)\n",
        "print(\"due_tasks\", [x[\"id\"] for x in dtasks])\n",
        "\n",
        "secret = \"s\"\n",
        "payload = b\"hello\"\n",
        "expect = hmac.new(secret.encode(), payload, hashlib.sha256).hexdigest()\n",
        "print(\"hmac\", verify_signature(secret, payload, expect), verify_signature(secret, payload, \"deadbeef\"))\n",
        "\n",
        "w = weekly_conversion(leads)\n",
        "print(\"weekly\", w[0][\"total\"] if w else 0)\n",
        "\n",
        "lru = LRU(2)\n",
        "lru.put(\"a\",1); lru.put(\"b\",2); lru.get(\"a\"); lru.put(\"c\",3)\n",
        "print(\"lru\", lru.get(\"b\") is None, lru.get(\"a\"))\n",
        "\n",
        "m, dff = merge_records({\"name\":\"X\",\"email\":\"\",\"phone\":\"111\"},{\"name\":\"\",\"email\":\"x@a.com\",\"phone\":\"111\"},\"a\")\n",
        "print(\"merge\", m[\"email\"], \"email\" in dff)\n",
        "\n",
        "print(\"rbac\", can(\"write:own\",\"rep\",\"u1\",\"u1\"), can(\"write:any\",\"admin\",\"u1\",\"u2\"))\n",
        "\n",
        "print(\"leads_month\", leads_per_owner_month(leads)[:2])\n",
        "\n",
        "sent = []\n",
        "async def demo_mail():\n",
        "    mailer = Mailer()\n",
        "    t = asyncio.create_task(mailer.run(lambda m: sent.append(m)))\n",
        "    await mailer.enqueue({\"to\":\"a\",\"sub\":\"hi\"})\n",
        "    await mailer.enqueue({\"to\":\"b\",\"sub\":\"yo\"})\n",
        "    await asyncio.sleep(0.05)\n",
        "    await mailer.q.join()\n",
        "    t.cancel()\n",
        "    try:\n",
        "        await t\n",
        "    except asyncio.CancelledError:\n",
        "        pass\n",
        "\n",
        "try:\n",
        "    loop = asyncio.get_running_loop()\n",
        "    if loop.is_running():\n",
        "        await demo_mail()\n",
        "    else:\n",
        "        asyncio.run(demo_mail())\n",
        "except RuntimeError:\n",
        "    asyncio.run(demo_mail())\n",
        "\n",
        "print(\"mail\", len(sent))\n",
        "\n",
        "csv_opps = export_opportunities_csv(opps, \"2025-01-01T00:00:00\")\n",
        "print(\"export_len\", len(csv_opps.splitlines()))\n",
        "\n",
        "res_imp = import_contacts_csv_text(\"email,name\\nz@z.com,Z\\nz@z.com,Z2\\n\", {})\n",
        "print(\"import_counts\", res_imp)\n",
        "\n",
        "audit_log = []\n",
        "ent = {\"id\":\"1\",\"name\":\"Old\"}\n",
        "print(\"audit\", apply_update_with_audit(ent, {\"name\":\"New\"}, \"u1\", audit_log)[\"name\"], len(audit_log))\n",
        "\n",
        "sync_store = {}\n",
        "sync_res = sync_external_contacts([{\"email\":\"A@EXAMPLE.COM\",\"phone\":\"(212) 555-0001\",\"name\":\"A1\",\"updated_at\":\"2025-08-10T09:00:00\"}], sync_store)\n",
        "print(\"sync\", sync_res[\"added\"], sync_res[\"updated\"])\n",
        "\n",
        "funnel = funnel_metrics(leads, opps)\n",
        "print(\"funnel\", funnel[\"leads\"], funnel[\"opportunities\"], funnel[\"won\"])\n",
        "\n",
        "page, nxt = search_and_page_contacts(contacts, \"user1\", 3, None)\n",
        "print(\"search_page\", [x[\"id\"] for x in page], bool(nxt))\n",
        "\n",
        "ret = monthly_cohort_retention(logins)\n",
        "print(\"retention_rows\", len(ret))\n",
        "\n",
        "us = {}\n",
        "print(\"upsert\", upsert_contact(us, {\"id\":\"10\",\"email\":\"A@EXAMPLE.COM\",\"phone\":\"\"})[\"email\"])\n",
        "\n",
        "sv2, dup2 = dedupe_contacts_simpler(contacts)\n",
        "print(\"unionfind\", len(sv2), len(dup2) >= len(dup))\n",
        "\n",
        "lead = create_lead(LeadIn(email=\"demo@x.com\", name=\"Demo\", source=\"ads\"), idempotency_key=\"k1\")\n",
        "lead2 = create_lead(LeadIn(email=\"demo@x.com\", name=\"Demo\", source=\"ads\"), idempotency_key=\"k1\")\n",
        "print(\"api_idem\", lead[\"email\"], lead2[\"email\"])\n",
        "\n",
        "print(\"done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOQgdWwKieIN",
        "outputId": "934b7a09-4551-4923-a918-c0b143202573"
      },
      "id": "lOQgdWwKieIN",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dedupe 30 0\n",
            "csv_upsert 2 1 X2\n",
            "rate True True False True\n",
            "idem 42 42 1\n",
            "page 5 True 5 True\n",
            "due_tasks ['4', '11', '2', '10', '13']\n",
            "hmac True False\n",
            "weekly 2\n",
            "lru True 1\n",
            "merge x@a.com True\n",
            "rbac True True\n",
            "leads_month [{'owner_id': 'u1', 'month': '2025-07', 'total': 1}, {'owner_id': 'u2', 'month': '2025-07', 'total': 3}]\n",
            "mail 2\n",
            "export_len 11\n",
            "import_counts {'added': 1, 'updated': 1}\n",
            "audit New 1\n",
            "sync 1 0\n",
            "funnel 20 10 5\n",
            "search_page ['12', '15', '14'] True\n",
            "retention_rows 2\n",
            "upsert a@example.com\n",
            "unionfind 28 True\n",
            "api_idem demo@x.com demo@x.com\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1981443411.py:246: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  audit_log.append({\"at\": datetime.utcnow().isoformat(),\"user_id\": user_id,\"entity_id\": str(entity.get(\"id\",\"\")),\"before\": before,\"after\": after})\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}